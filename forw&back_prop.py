# -*- coding: utf-8 -*-
"""forw&back-prop.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1UDN18c6MpMylwWxEWA4UxmtJ1cHCyUss
"""

# Commented out IPython magic to ensure Python compatibility.
import math
import numpy as np
import matplotlib.pyplot as plt
# %matplotlib inline

def f(x):
  """
  Scalar value function, takes a single scalar (number representing magnitude or quantity) x and returns single scalar y
  """
  return 3*x**2 - 4*x + 5

f(3.0)

xs = np.arange(-5, 5, 0.25) # An array of the range from -5 to 5 with steps of 0.25 (not including 5)
ys = f(xs) # Array gets mapped as the input, and function gets applied individually for each elelment
           # returns an array with the results
ys

plt.plot(xs, ys) # x, y

h = 0.00000001 # Very close to zero
x = -3.0 #Our target val
f(x+h) # Slightly nudge x in a positive direction
# But how does it respond?
(f(x+h) - f(x))/h # This is how much it responded, and u normalize it via the run (rise/run for slope -> the direction it is changing or going in)
#Gives numerical representation of the slope, and closer to zero will tell u the value

# 3 scalars, and output variable d from them
a = 2.0
b = -3.0
c = 10.0
d = a * b + c
print(d)

h = 0.00001 # very small & close to zero

# inputs that are random vals
a = 2.0
b = -3.0
c = 10.0


d1 = a * b + c
a += h # bumping our input by a tiny amount
d2 = a * b + c

print('d1', d1)
print('d2', d2) # decreases, thus the slope is negative
print('slope', (d2-d1)/h) #how much the function increased from d1 to d2, then normalized for the slope

class Value:
  """
  Takes a single scalar value, to keep track of (essentially wraps it)

  Scalar value is taking in via data, and it is wrapped in the class via -> self.data

  The double underscore is used to define the operators of the functions, and are automatically called via interepreter
  aka magic function. This allows them to replace certain things or have things happen in a manner when something is done.

  Example:
  __repr__: provides the string representation of the object
  __add__: allows u to define the behavior of the addition operator when used with objects of the class
  """
  def __init__(self, data, _children=(), _op=''): # creating children as an immutable list
    self.data = data
    self.grad = 0.0 # Maintains the derivative of the output/loss func in respect to the current val
    # Being intialized to zero, so we assume it doesnt have an effect on the output

    self._prev = set(_children) # set to remove duplicates
  #  Need connective tissue, and want to make this a graph --
  # so we need pointers to know what values create other values
  # Thus prev is introduced
    self._op = _op


  def __repr__(self):
    return f"Value(data={self.data})"

  def __add__(self, other):
    """
    Takes another value, and takes its sellf and then gets its own value and adds it to the other and returns it
    """
    out = Value(self.data + other.data, (self, other), '+') # feed in children of the val, which is a tuple of itself and other
    return out

  def __mul__(self, other):
    out = Value(self.data * other.data , (self, other), '*') # feed in children of the val, which is a tuple of itself and other
    return out

a = Value(2.0)
b = Value(-3.0)
c = Value(10.0)
e = a*b
d = e + c
f = Value(-2.0)
L = d * f
# Self is a in this instance, and b is the other
# Which is the same as (a.mul(b)).add(c)

L._prev # set of children, which is (a*b) and c

L._op # d was made via addition of the two values

# Now we have a datastructure where we know exactly how each value came to be, like what numbers made it and what operation

# We essentially have a forward-pass know, we know exactly what two values made one, and through what operation.
# and we can get an output based on all these values

# Next we need backpropagation, so we would start at the output (or the end) and go back and calculate the gradient at each layer
# or each values. The calculation that we're actually doing is the derivative of the value with respect to the output/loss func.

# In the case of a NN youd be wanting to do the derivative of the loss function to each of the neurons weights. The Data is fixed
# but the weights are iterated on.

def lol():
  """
  We can easily calculate the derivative of whichever number we add h to with respect to L
  """

  h = 0.0001

  a = Value(2.0)
  b = Value(-3.0)
  c = Value(10.0)
  e = a*b
  d = e + c
  f = Value(-2.0)
  L = d * f
  L1 = L.data

  a = Value(2.0)
  b = Value(-3.0)
  c = Value(10.0)
  e = a*b
  d = e + c
  f = Value(-2.0)
  L = d * f
  L2 = L.data  + h

  print((L2 - L1)/h) # This is the derivative of d with respect to d, whichever u number u add h to it will be in respect to that

lol()

# We can now calculate the gradients of each, by taking the derivative with respect to the output. And in order to
# take the gradient of a value that isnt next to the output we need to use the chain rule of derivative, which is calculating
# the local derivative of the previos value and current and multiplying that by derivative current value wtih respect to the output

L.grad = 1.0 # Derivative of L with respect to L

f.grad = 4.0 # Derivative of f with respect to L

d.grad = -2.0 # Derivative of d with respect to L

c.grad = -2.0 # Derivative of c with respect to d multiplied by derivative of c with respect to L

e.grad = -2.0 # Derivative of e with respect to d multiplied by derivative of c with respect to L

a.grad = 6.0 # Derivative of a with respect to e multiplied by derivative of e with respect to L

b.grad = 4.0 # Derivative of b with respect to e multiplied by derivative of e with respect to L

# The respective gradients mean that by increasing them by a small amount the loss function would increase by that amount

# For example for b the gradient is 4, and increasing its weight by a small amount would increase the loss function by
# 4.0 times the amount.

# That would mean that this weight is making the loss higher, and needs to be decreased.
# Thus, you would set the new weight to the old weight - learning rate * the gradient
# This formula is the same whether the gradient is postiive or negative.

# Effectively moving the weight in the direction that decreases the loss

# Now we are going to nudge/change our values to try to make L go up (essentially improve accuracy)

# Since we want L to go up, we go in the direc of the gradient
# Thus a should increase in the direction by a small step amount

w = 0.01 # Our step size or Learning Rate, and the size of the step taken towards the min (if too small, it might get stuck, or too large itll overshoot)

# Nudge the leaf nodes which we have control over

a.data += a.grad + w
b.data += a.grad + w
c.data += a.grad + w
f.data += a.grad + w

# This is basically one step of an optimization in order to make the outcome more positive